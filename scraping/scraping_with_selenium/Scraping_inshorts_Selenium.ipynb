{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e72fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_html(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content,\"html.parser\")\n",
    "    time.sleep(5) \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_inshorts_web(soup):\n",
    "    \n",
    "    articles = soup.find_all(\"div\",attrs={\"class\":\"news-card z-depth-1\"})\n",
    "    \n",
    "    # Declaration\n",
    "    articles_topic = []\n",
    "    articles_content = []\n",
    "\n",
    "    for article in articles:\n",
    "        # Get article's topic\n",
    "        topic = article.find(\"span\",attrs={\"itemprop\":\"headline\"}).get_text()\n",
    "        articles_topic.append(topic)\n",
    "        \n",
    "        # Get article's content\n",
    "        content = article.find('div',attrs={'itemprop':'articleBody'}).get_text()\n",
    "        articles_content.append(content) \n",
    "        \n",
    "    return articles_topic, articles_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_to_csv(topic, category, content):\n",
    "    # Create dataframe\n",
    "    data = pd.DataFrame({\n",
    "    \"topic\": topic,\n",
    "    \"category\": category,\n",
    "    \"content\": content\n",
    "    })\n",
    "    data.to_csv(f'inshorts Scraping-{category}-{datetime.now().strftime(\"%d-%m-%Y\")}.csv', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"sports\", \"world\", \"politics\", \"technology\", \"startup\", \"entertainment\", \"science\"]\n",
    "print(\"Start scraping from inshorts!\")\n",
    "for category in categories:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(f\"https://www.inshorts.com/en/read/{category}\")\n",
    "    driver.maximize_window()  \n",
    "    for i in range (1, 20):\n",
    "        time.sleep(5)\n",
    "        button_xpath = \"//div[@class='clickable unselectable load-more z-depth-1 hoverable']\"  \n",
    "        driver.find_element(by=By.XPATH, value=button_xpath).click()                    \n",
    "        time.sleep(5)\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    topic, content = get_data_inshorts_web(soup)\n",
    "    insert_data_to_csv(topic, category, content)\n",
    "print(\"Finish scraping from inshorts.com!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
