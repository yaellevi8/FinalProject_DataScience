{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e72fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e61fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_html(url):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content,\"html.parser\")\n",
    "    time.sleep(30) \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f314dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_moneycontrol_web(soup):\n",
    "    all_articles = soup.find('ul',attrs={'id':'cagetory'}).find_all('li',attrs={'class':'clearfix'})\n",
    "    \n",
    "    # Declaration\n",
    "    articles_topic = []\n",
    "    articles_content = []\n",
    "    \n",
    "    for article in all_articles:\n",
    "            topic = article.find('h2').find('a').get_text()\n",
    "            \n",
    "            url_of_article = article.find('h2').find('a')['href']\n",
    "            soup = get_article_html(url_of_article)\n",
    "            \n",
    "            if soup.find('div',attrs={'class':'content_wrapper arti-flow'}) != None:\n",
    "                content = soup.find('div',attrs={'class':'content_wrapper arti-flow'}).find_all(\"p\")\n",
    "                full_content = \"\"\n",
    "                if content != None:\n",
    "                    for paragraph in content:\n",
    "                        full_content = full_content + \" \" + paragraph.get_text().strip()\n",
    "                        \n",
    "                articles_topic.append(topic)\n",
    "                articles_content.append(full_content)            \n",
    "\n",
    "    return articles_topic, articles_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4dd7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_to_csv(topic, category, content):\n",
    "    # Create dataframe\n",
    "    data = pd.DataFrame({\n",
    "    \"topic\": topic,\n",
    "    \"category\": category,\n",
    "    \"content\": content\n",
    "    })\n",
    "    data.to_csv(f'moneycontrol Scraping-{category}-{datetime.now().strftime(\"%d-%m-%Y\")}.csv', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c70176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start scraping from moneycontrol!\n"
     ]
    }
   ],
   "source": [
    "categories = [\"markets\", \"stocks\", \"companies\", \"trends\", \"business\", \"economy\"]\n",
    "\n",
    "print(\"Start scraping from moneycontrol!\")\n",
    "\n",
    "def scraping_with_selenium_from_url(url):\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        time.sleep(30)\n",
    "        driver.maximize_window()\n",
    "        time.sleep(30)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,\"html.parser\")\n",
    "        topic, content = get_data_moneycontrol_web(soup)\n",
    "        insert_data_to_csv(topic, category, content)\n",
    "        next_button = driver.find_element(by=By.LINK_TEXT, value=('»')).click()\n",
    "        for i in range (1, 28): \n",
    "            time.sleep(30)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html,\"html.parser\")\n",
    "            topic, content = get_data_moneycontrol_web(soup)\n",
    "            insert_data_to_csv(topic, category, content)\n",
    "            next_button = driver.find_element(by=By.LINK_TEXT, value=('»')).click()\n",
    "        driver.close()\n",
    "        \n",
    "for category in categories:\n",
    "    if category in (\"economy\", \"markets\", \"stocks\", \"companies\"):\n",
    "        scraping_with_selenium_from_url(f\"https://www.moneycontrol.com/news/business/{category}\")\n",
    "    else:\n",
    "        scraping_with_selenium_from_url(f\"https://www.moneycontrol.com/news/{category}\")\n",
    "\n",
    "print(\"Finish scraping from moneycontrol.com!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b869ccb-531c-4319-9562-da1fadddd076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
